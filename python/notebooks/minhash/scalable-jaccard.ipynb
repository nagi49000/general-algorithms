{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9384507d",
   "metadata": {},
   "source": [
    "# Scalable Jaccard neighbour finding\n",
    "\n",
    "## Jaccard clustering\n",
    "\n",
    "A standard technique of handling document similarity or clustering is to tokenize the data, and then cluster on the tokens of each document. On small scales, this is relatively easy to get running in a notebook environment.\n",
    "\n",
    "A tokenizer maps each document to a set of tokens\n",
    "\n",
    "$ t : d_i \\rightarrow \\{t(d_i)_j\\}_{j=1}^{n_i} = \\{t_{ij}\\}_{j=1}^{n_i}$\n",
    "\n",
    "A tokenizer can be as elaborate or as simple as one wishes. Perhaps the simplest is breaking up a document over sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06583d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am', 'a', 'fish'], ['a', 'fish', 'swims']]\n"
     ]
    }
   ],
   "source": [
    "docs = [\"I am a fish\", \"a fish swims\"]\n",
    "tokenized_docs = [x.split(\" \") for x in docs]\n",
    "print(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cdf0ef",
   "metadata": {},
   "source": [
    "Using the tokens, one can estimate how similar documents might be. A typical way of seeing the similarity is by a Jaccard similarity. This looks at (between a pair of documents) the number of common tokens divided by the number of all tokens\n",
    "\n",
    "$ J_{sim}(d_x, d_y) = \\frac{\\{t_{xj}\\}_{j=1}^{n_x} \\cap \\{t_{yj}\\}_{j=1}^{n_y}}{\\{t_{xj}\\}_{j=1}^{n_x} \\cup \\{t_{yj}\\}_{j=1}^{n_y}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5f121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(d_x, d_y):\n",
    "    return len(set(d_x) & set(d_y)) / len(set(d_x) | set(d_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3cf236",
   "metadata": {},
   "source": [
    "For identical sets, the Jaccard similarity will be 1. For sets with no tokens in common, the similarity will be 0. For sets with some tokens in common, the similarity will be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101d031d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_sim(tokenized_docs[0], tokenized_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1a7a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_sim(tokenized_docs[0], tokenized_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b24f46",
   "metadata": {},
   "source": [
    "From the similarity, one can define a distance, the Jaccard distance by\n",
    "\n",
    "$J_{dist}(d_x, d_y) = 1 - J_{sim}(d_x, d_y)$.\n",
    "\n",
    "This distance function forms a proper metric [[1]](https://en.wikipedia.org/wiki/Metric_space), i.e. it observes the distance function rules:\n",
    "- $ J_{dist}(d_x, d_x) = 0 $\n",
    "- $ J_{dist}(d_x, d_y) > 0 \\textrm{  for  } d_x \\neq d_y $\n",
    "- $ J_{dist}(d_x, d_y) = J_{dist}(d_y, d_x) $\n",
    "- $ J_{dist}(d_x, d_z) \\leq J_{dist}(d_x, d_y) + J_{dist}(d_y, d_z) $\n",
    "\n",
    "which means that the distance metric can legitimately be used in clustering. One can play the usual games with hierarchical clustering etc. In particular, for simple clustering, one can find a documents neighbours by thresholding on the distance, and describing the neighbours of a document as the other documents with a threshold distance $T$ of that document:\n",
    "\n",
    "$ \\textrm{neighbours}(d_i) = \\{d_j | J_{dist}(d_i, d_j) < T \\}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35aab6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours(this_doc, all_docs, threshold, tokenizer=lambda x: x.split(\" \")):\n",
    "    this_tokenized_docs = tokenizer(this_doc)\n",
    "    all_tokenized_docs = [tokenizer(x) for x in all_docs]\n",
    "    neighbours = [y[0] for y in zip(all_docs, all_tokenized_docs) if (1 - jaccard_sim(y[1], this_tokenized_docs)) < threshold]\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c11b07bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am a fish']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbours(\"I a am fish\", docs, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be8e39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am a fish', 'a fish swims']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbours(\"I a am fish\", docs, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24609fd7",
   "metadata": {},
   "source": [
    "The simple implementations above work well for small datasets. However, for large datasets, the computation of distances, or finding nearest neighbours, is $O(N^2)$ where $N$ is the number of documents. Depending on how the results are stored, storage can also be a $N^2 $ problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c73c0b1",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] https://en.wikipedia.org/wiki/Metric_space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
